{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, Embedding,Dropout\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.preprocessing.text import Tokenizer\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "import re\n",
                "import pickle\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Vocab size: 12848\n",
                        "Sequence length: 50\n",
                        "Embedding dim: 100\n"
                    ]
                }
            ],
            "source": [
                "#load data from files\n",
                "X = np.load('../data/X.npy')\n",
                "y = np.load('../data/y.npy')\n",
                "with open('../data/tokenizer.pkl', 'rb') as f:\n",
                "    tokenizer = pickle.load(f)\n",
                "\n",
                "# Calculate variables needed for the model\n",
                "vocab_size = len(tokenizer.word_index) + 1\n",
                "max_sequence_length = X.shape[1]\n",
                "embedding_dim = 100 # Define embedding dimension\n",
                "\n",
                "print(f\"Vocab size: {vocab_size}\")\n",
                "print(f\"Sequence length: {max_sequence_length}\")\n",
                "print(f\"Embedding dim: {embedding_dim}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Train a LSTM to predict the next word in a sequence of words**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1mModel: \"sequential\"\u001b[0m\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,800</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12848</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,657,392</span> │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
                            "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
                            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
                            "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │     \u001b[38;5;34m1,284,800\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m117,248\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
                            "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
                            "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12848\u001b[0m)          │     \u001b[38;5;34m1,657,392\u001b[0m │\n",
                            "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,059,440</span> (11.67 MB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,059,440\u001b[0m (11.67 MB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,059,440</span> (11.67 MB)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,059,440\u001b[0m (11.67 MB)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "model = Sequential()\n",
                "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
                "\n",
                "# LSTM Layer\n",
                "# return_sequences=False because we want a single vector output (Many-to-One) for the next word\n",
                "model.add(LSTM(units=128, return_sequences=False)) \n",
                "model.add(Dropout(0.2))\n",
                "\n",
                "model.add(Dense(units=vocab_size, activation='softmax'))\n",
                "\n",
                "# Build the model to verify architecture\n",
                "model.build(input_shape=(None, max_sequence_length))\n",
                "\n",
                "# Using sparse_categorical_crossentropy since y is not one-hot encoded\n",
                "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 1/5\n",
                        "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 263ms/step - accuracy: 0.0435 - loss: 6.7304 - val_accuracy: 0.0627 - val_loss: 6.7943\n",
                        "Epoch 2/5\n",
                        "\u001b[1m2533/2533\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m893s\u001b[0m 346ms/step - accuracy: 0.0796 - loss: 6.2089 - val_accuracy: 0.0775 - val_loss: 6.7288\n",
                        "Epoch 3/5\n",
                        "\u001b[1m1523/2533\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:27\u001b[0m 264ms/step - accuracy: 0.0906 - loss: 5.9254"
                    ]
                }
            ],
            "source": [
                "history = model.fit(X, y, epochs=5, batch_size=64, validation_split=0.2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.plot(history.history['accuracy'], label='accuracy')\n",
                "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save('../saved_models/lstm_model.h5')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
